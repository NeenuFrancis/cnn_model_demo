{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6U6sqKu7Hfe",
        "outputId": "8613a98f-4f5e-4cde-c787-18ab2281b831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'friends_multiclass_CNN'...\n",
            "remote: Enumerating objects: 176, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 176 (delta 1), reused 0 (delta 0), pack-reused 143\u001b[K\n",
            "Receiving objects: 100% (176/176), 2.82 MiB | 13.56 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/NeenuFrancis/friends_multiclass_CNN.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkIw46LPeGAc"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!git clone https://github.com/NeenuFrancis/friends_multiclass_CNN\n",
        "#!rm -rf /content/friends_multiclass_CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCV30xyVhFbE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FIleuCAjoFD8",
        "outputId": "ea7ab7e7-f527-4ad0-cd3a-a239e3f1115a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.14.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1 - Data Preprocessing**\n",
        "\n"
      ],
      "metadata": {
        "id": "Go-LCQvzt56X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Training set"
      ],
      "metadata": {
        "id": "_nN0vlOTvHLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "YVHOAkIBQwT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "#Creating an object of ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   validation_split=0.1)\n",
        "\n",
        "#Generating batches of Augmented data\n",
        "training_set = train_datagen.flow_from_directory('/content/friends_multiclass_CNN/Data/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical'\n",
        "                                                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K8vBUFSt-sG",
        "outputId": "d178c6aa-0f72-4a96-e934-c09db34c3de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 45 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Test set"
      ],
      "metadata": {
        "id": "-ikhQLjsvT8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255,validation_split=0.1)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/friends_multiclass_CNN/Data/Test',\n",
        "                                             target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical'\n",
        "                                            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c_CryLkvS1H",
        "outputId": "a6d85120-d1f6-41dc-a416-7400ba7a7db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2 - Building the CNN**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K56vilF6xdcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising the CNN"
      ],
      "metadata": {
        "id": "lxc2uA8Gx1Oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "7wuj966mx2sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 - Convolution"
      ],
      "metadata": {
        "id": "kqoFz1J6yDB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu',\n",
        "                               input_shape=[64, 64, 3]))\n"
      ],
      "metadata": {
        "id": "YW2xKjlSyD29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 - Pooling"
      ],
      "metadata": {
        "id": "aQqI04ekyI99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "jt4KfyrvyKOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a second convolutional layer"
      ],
      "metadata": {
        "id": "G1AJMfiayQkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "NWwL4UtvySl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 - Flattening"
      ],
      "metadata": {
        "id": "T8LUay2eyX2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "Rt6DoMidyYtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 - Full Connection"
      ],
      "metadata": {
        "id": "QV4ofYcYyezd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "bSTx2oViybKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 - Output Layer"
      ],
      "metadata": {
        "id": "1cRM8YV_ylsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=5, activation='softmax'))"
      ],
      "metadata": {
        "id": "FFLwj12FymeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3 - Training the CNN**"
      ],
      "metadata": {
        "id": "kHBcsTSSyrcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the CNN"
      ],
      "metadata": {
        "id": "2BbMojc4ywzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "NBZ4ugEayxuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ],
      "metadata": {
        "id": "utSxqtJay38m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKvF7gO33zqO",
        "outputId": "3496bb72-8405-495b-e757-5373c5791e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2/2 [==============================] - 14s 1s/step - loss: 1.7319 - accuracy: 0.2222 - val_loss: 1.2417 - val_accuracy: 0.4706\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.3120 - accuracy: 0.2889 - val_loss: 1.3090 - val_accuracy: 0.3529\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 359ms/step - loss: 1.2338 - accuracy: 0.3111 - val_loss: 1.0847 - val_accuracy: 0.6471\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.0982 - accuracy: 0.5778 - val_loss: 0.9126 - val_accuracy: 0.6471\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 0.9836 - accuracy: 0.6000 - val_loss: 0.7879 - val_accuracy: 0.6471\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 248ms/step - loss: 0.7831 - accuracy: 0.6000 - val_loss: 0.7522 - val_accuracy: 0.7647\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 224ms/step - loss: 0.7506 - accuracy: 0.8000 - val_loss: 0.6501 - val_accuracy: 0.7647\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.6165 - accuracy: 0.8222 - val_loss: 0.4640 - val_accuracy: 0.8235\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 0.5232 - accuracy: 0.8222 - val_loss: 0.4043 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 348ms/step - loss: 0.4402 - accuracy: 0.8667 - val_loss: 0.3423 - val_accuracy: 0.8235\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 0.3158 - accuracy: 0.8889 - val_loss: 0.2431 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 345ms/step - loss: 0.2305 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 397ms/step - loss: 0.1689 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 346ms/step - loss: 0.1364 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 230ms/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 357ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 374ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 593ms/step - loss: 0.0735 - accuracy: 0.9778 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 471ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 376ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f3cb3f391b0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = tf.keras.utils.load_img('/content/friends_multiclass_CNN/Predict_Image/WhatsApp Image 2023-11-01 at 8.58.33 PM.jpeg',\n",
        "                                     target_size = (64, 64))\n",
        "#test_image = tf.keras.utils.load_img(test_image)\n",
        "im=test_image\n",
        "\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "result = cnn.predict(test_image)\n",
        "\n",
        "training_set.class_indices\n",
        "\n",
        "\n",
        "label=[\"Benson\", \"Leena\", \"Michelle\", \"Neenu\",\"Sam\"]\n",
        "for i in label:\n",
        "    if result[0][label.index(i)]==1:\n",
        "         break\n",
        "\n",
        "\n",
        "\n",
        "prediction=i\n",
        "\n",
        "\n",
        "im.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMwwIWduEx18",
        "outputId": "be5892ce-6214-4388-d4df-0d9608ba54f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 151ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)\n",
        "\n",
        "display(im)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "eg3aAg3kUGo0",
        "outputId": "7df56297-8402-4b65-b318-12c2b02867b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Michelle\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}